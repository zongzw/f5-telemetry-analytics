version: "3"

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.4.1
    container_name: ELASTICSEARCH
    ports:
      - 9200:9200
    environment:
      - discovery.type=single-node
    volumes:
     - ${HOMEDIR}/data/elasticsearch:/usr/share/elasticsearch/data
    # entrypoint:
    #   - /usr/local/bin/docker-entrypoint.sh
    #   - eswrapper

  fluentd:
    build: ${HOMEDIR}/docker/fluentd
    image: f5networks/fluentd:latest
    container_name: FLUENTD
    ports:
      # - 24224:24224
      # - 24224:24224/udp
      - 20001:20001/udp
      # - 8081-8089:8081-8089
      # - 8085:8085
    volumes:
      - ${HOMEDIR}/conf.d/fluentd.conf:/etc/td-agent/td-agent.conf
      - ${HOMEDIR}/conf.d/fluentd:/etc/td-agent/fluentd
      - ${HOMEDIR}/scripts/cmds-in-fluentd:/root/cmds-in-fluentd
      - ${HOMEDIR}/conf.d/fluentd-crontab:/etc/crontab
    depends_on:
      - elasticsearch
      - kibana
      - kafka

  kibana:
    image: docker.elastic.co/kibana/kibana:7.4.1
    container_name: KIBANA
    depends_on:
      - elasticsearch
    ports:
      - 5601:5601
    volumes:
      - ${HOMEDIR}/conf.d/kibana.yml:/usr/share/kibana/config/kibana.yml
      - ${HOMEDIR}/data/kibana:/usr/share/kibana/data
    # entrypoint:
    #   - /usr/local/bin/dumb-init
    #   - --
    #   - /usr/local/bin/kibana-docker

  ctrlbox:
    build: ${HOMEDIR}/docker/ctrlbox
    image: f5networks/ctrlbox:latest
    container_name: CTRLBOX
    ports:
      - 8000:80
    depends_on:
      - nginx
      - kibana
      - elasticsearch
      - fluentd
      - kafka
      - logstash
    env_file:
      - ${HOMEDIR}/conf.d/.setup.rc
    volumes:
      - ${HOMEDIR}:/root/workdir
      - ${HOMEDIR}/conf.d/ctrlbox-crontab:/etc/crontab
      # - ${HOMEDIR}/scripts:/root/scripts
      # - ${HOMEDIR}/conf.d/setup.rc:/root/setup.rc # temp
      # - ${HOMEDIR}/conf.d/kibana-exports:/root/kibana-exports
    # entrypoint:
    #   - /bin/sh
    #   - -c
    #   - while true; do sleep 1; done

  # zookeeper:
  #   image: wurstmeister/zookeeper:latest
  #   expose:
  #   - "2181"

  # kafka:
  #   image: wurstmeister/kafka:2.12-2.4.0
  #   depends_on:
  #   - zookeeper
  #   ports:
  #   - "9092:9092"
  #   environment:
  #     # KAFKA_BROKER_ID: 1
  #     # BROKER_ID_COMMAND: "printf '%d' $((0x$HOSTNAME % 10000))"
  #     HOSTNAME_COMMAND: "hostname"
  #     KAFKA_ADVERTISED_HOST_NAME: _{HOSTNAME_COMMAND}
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
  #     KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
  #     KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
  #     # KAFKA_CREATE_TOPICS: "messages:1:1,test:1:1:compact"
  #     # KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
  #     # KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
  #     # KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

  zookeeper:
    image: bitnami/zookeeper:3
    container_name: ZOOKEEPER
    ports:
      - 2181:2181
    # volumes:
    #   - ${HOMEDIR}/data/zookeeper:/bitnami
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    
  kafka:
    image: bitnami/kafka:2
    container_name: KAFKA
    ports:
      - 9092:9092
      - 9093:9093
    volumes:
      - ${HOMEDIR}/data/kafka:/bitnami/kafka
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka:9093,EXTERNAL://localhost:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=EXTERNAL:PLAINTEXT,INTERNAL:PLAINTEXT
      - KAFKA_CFG_LISTENERS=INTERNAL://kafka:9093,EXTERNAL://localhost:9092
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INTERNAL
      # fix error of fluentd: error_class=Kafka::MessageSizeTooLarge error="Kafka::MessageSizeTooLarge"
      - KAFKA_CFG_MESSAGE_MAX_BYTES=1073741824 # 1G
      # data retention settings
      - KAFKA_CFG_LOG_RETENTION_CHECK_INTERVAL_MS=10000 # 10s
      - KAFKA_CFG_LOG_RETENTION_HOURS=1 # 1hour
      - KAFKA_CFG_LOG_RETENTION_BYTES=1073741824  #1GB
    depends_on:
      - zookeeper

      # KAFKA_ADVERTISED_HOST_NAME: kafka
      # KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      # KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      # KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      # KAFKA_CREATE_TOPICS: "messages:1:1,test:1:1:compact"

      # KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9093,OUTSIDE://localhost:9092
      # KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      # KAFKA_LISTENERS: INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092
      # KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      # KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE

  logstash:
    build: ${HOMEDIR}/docker/logstash
    image: f5networks/logstash:latest
    container_name: LOGSTASH
    depends_on:
      - elasticsearch
    ports:
      # - 4560:4560 # for logstash debug test.
      # - 5000:5000
      - 9600:9600
    volumes:
      - ${HOMEDIR}/conf.d/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
      - ${HOMEDIR}/conf.d/logstash.pipelines:/usr/share/logstash/config/pipelines.yml
    entrypoint:
      - /usr/local/bin/docker-entrypoint
      - -r    # Make logstash reload automatically when conf. changes.
    
    
  nginx:
    image: nginx:latest
    container_name: NGINX
    ports:
      - 20000:20000/udp
    volumes:
      - ${HOMEDIR}/conf.d/nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - fluentd
